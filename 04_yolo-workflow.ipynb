{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a95e5e59-d364-4649-aa01-d1fad48be0d0",
   "metadata": {},
   "source": [
    "# 4. Wild fire smoke detection용 yolov8n 모델 pipeline 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a614cd4-1e4a-4e97-801e-2f0e85528bc3",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250480fd-f58c-4050-853f-653434a2f397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import datetime\n",
    "\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.model import ModelPackage\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.lambda_step import LambdaStep\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.model_metrics import ModelMetrics\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.processing import (\n",
    "    ScriptProcessor, \n",
    "    FrameworkProcessor, \n",
    "    ProcessingInput, \n",
    "    ProcessingOutput\n",
    ")\n",
    "from sagemaker.workflow.steps import (\n",
    "    TrainingStep, \n",
    "    ProcessingStep\n",
    ")\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "from sagemaker.workflow.parameters import ( \n",
    "    ParameterInteger, \n",
    "    ParameterString, \n",
    "    ParameterFloat\n",
    ")\n",
    "\n",
    "SAGEMAKER_SESSION = sagemaker.session.Session()\n",
    "ROLE = sagemaker.get_execution_role()\n",
    "PIPELINE_SESSION = PipelineSession()\n",
    "default_bucket = SAGEMAKER_SESSION.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e4528f-f566-4ce6-b55d-58d2fef2c56f",
   "metadata": {},
   "source": [
    "# SETTING UP INPUTS AND IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d019b689-0252-40f1-bed5-db997f5c7248",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket_param = ParameterString(name=\"S3Bucket\", default_value=\"sagemaker-us-east-1-211125368524\")\n",
    "s3_folder_param = ParameterString(name=\"S3Folder\", default_value=\"wildfire_smoke\")\n",
    "train_ratio_param = ParameterFloat(name=\"TrainTestRatio\", default_value=0.8)\n",
    "\n",
    "model_param = ParameterString(name='Model', default_value='yolov8n.pt')\n",
    "epochs_param = ParameterInteger(name='Epochs', default_value=10)\n",
    "batch_size_param = ParameterInteger(name='BatchSize', default_value=2)\n",
    "patience_param = ParameterInteger(name='Patience', default_value=100)\n",
    "optimizer_param = ParameterString(name='Optimizer', default_value='auto')\n",
    "ilr_param = ParameterFloat(name='InitialLearningRate', default_value=0.01)\n",
    "flr_param = ParameterFloat(name='FinalLearningRate', default_value=0.01)\n",
    "\n",
    "mAP_threshold = ParameterFloat(name='mAPThreshold', default_value=0.75)\n",
    "mAP50_threshold = ParameterFloat(name='mAP50Threshold', default_value=0.90)\n",
    "mAP75_threshold = ParameterFloat(name='mAP75Threshold', default_value=0.80)\n",
    "precisionthreshold = ParameterFloat(name='PrecisionThreshold', default_value=0.90)\n",
    "recallthreshold = ParameterFloat(name='RecallThreshold', default_value=0.80)\n",
    "model_package_name = ParameterString(name=\"ModelPackageName\", default_value='yolo-smoke-detection')\n",
    "\n",
    "\n",
    "PROCESSING_IMAGE = sagemaker.image_uris.retrieve(framework='pytorch', \n",
    "                                          region=SAGEMAKER_SESSION.boto_region_name, \n",
    "                                          version='2.2.0', \n",
    "                                          py_version='py310',\n",
    "                                          instance_type='ml.m5.2xlarge',\n",
    "                                          image_scope='training')\n",
    "\n",
    "TRAINING_IMAGE = sagemaker.image_uris.retrieve(framework='pytorch', \n",
    "                                          region=SAGEMAKER_SESSION.boto_region_name, \n",
    "                                          version='2.2.0', \n",
    "                                          py_version='py310', \n",
    "                                          instance_type='ml.g4dn.xlarge',#'ml.c2.2xlarge',\n",
    "                                          image_scope='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8675f0-7618-4a28-a8d8-0a371127ce34",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e08d6e2-4de1-44f5-9577-aaf03542acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "# zip 파일 경로\n",
    "zip_path = 'Wildfire Smoke.v1-raw.yolov8-obb.zip'\n",
    "\n",
    "folder_path = \"wildfire_smoke/\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# 압축 해제\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(folder_path)  # 현재 디렉토리에 압축 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78adaadf-5f24-43b0-ae56-31f13866e440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 prefix 'wildfire_smoke' already exists in bucket 'sagemaker-us-east-1-211125368524'. Skipping upload.\n"
     ]
    }
   ],
   "source": [
    "def check_s3_prefix_exists(bucket_name, s3_prefix):\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        # List objects with the given prefix\n",
    "        response = s3_client.list_objects_v2(\n",
    "            Bucket=bucket_name,\n",
    "            Prefix=s3_prefix,\n",
    "            MaxKeys=1\n",
    "        )\n",
    "        # If 'Contents' exists in response, the prefix exists and has objects\n",
    "        return 'Contents' in response\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking S3 prefix: {str(e)}\")\n",
    "        return False\n",
    "        \n",
    "def upload_directory_to_s3(local_directory, bucket_name, s3_prefix):\n",
    "    # First check if prefix exists\n",
    "    if check_s3_prefix_exists(bucket_name, s3_prefix):\n",
    "        print(f\"S3 prefix '{s3_prefix}' already exists in bucket '{bucket_name}'. Skipping upload.\")\n",
    "        return\n",
    "        \n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    # 로컬 디렉토리 내 모든 파일 순회\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for filename in files:\n",
    "            # 로컬 파일의 전체 경로\n",
    "            local_path = os.path.join(root, filename)\n",
    "            \n",
    "            # S3에 저장될 경로 생성\n",
    "            relative_path = os.path.relpath(local_path, local_directory)\n",
    "            s3_path = os.path.join(s3_prefix, relative_path).replace(\"\\\\\", \"/\")\n",
    "            \n",
    "            # 업로드 진행\n",
    "            try:\n",
    "                print(f\"Uploading {local_path} to {bucket_name}/{s3_path}\")\n",
    "                s3_client.upload_file(local_path, bucket_name, s3_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error uploading {local_path}: {str(e)}\")\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # 설정\n",
    "    LOCAL_DIR = \"wildfire_smoke/\"  # 업로드할 로컬 디렉토리\n",
    "    #BUCKET_NAME = \"sagemaker-us-east-1-211125368524\"           # S3 버킷 이름\n",
    "    S3_PREFIX = \"wildfire_smoke\"              # S3 내 저장될 경로\n",
    "    \n",
    "    # 업로드 실행\n",
    "    upload_directory_to_s3(LOCAL_DIR, default_bucket, S3_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6696ed-26ff-4565-a996-e16fbd41a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_processor = ScriptProcessor(\n",
    "    image_uri=PROCESSING_IMAGE,\n",
    "    command=['python3'],\n",
    "    role=ROLE,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.t3.xlarge',\n",
    "    sagemaker_session=SAGEMAKER_SESSION\n",
    ")\n",
    "\n",
    "processing_step = ProcessingStep(\n",
    "    name='YOLO-Preprocessing',\n",
    "    processor=script_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=Join(on='/', values=[\"s3:/\", s3_bucket_param, s3_folder_param]),\n",
    "            destination='/opt/ml/processing/input'\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name='train_data',\n",
    "            source='/opt/ml/processing/train',\n",
    "            destination=Join(on='/', values=[\"s3:/\", s3_bucket_param, s3_folder_param, \"train\"])\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name='val_data',\n",
    "            source='/opt/ml/processing/val',\n",
    "            destination=Join(on='/', values=[\"s3:/\", s3_bucket_param, s3_folder_param, \"val\"])\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name='test_data',\n",
    "            source='/opt/ml/processing/test',\n",
    "            destination=Join(on='/', values=[\"s3:/\", s3_bucket_param, s3_folder_param, \"test\"])\n",
    "        )\n",
    "    ],\n",
    "    code='yolo_code/smoke_preprocess.py',\n",
    "    job_arguments=[\n",
    "        '--s3-bucket', s3_bucket_param.to_string(),\n",
    "        '--s3-folder', s3_folder_param.to_string(),\n",
    "        '--train-ratio', train_ratio_param.to_string()\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac4b925-0399-4e47-968f-daa3b0fc98e2",
   "metadata": {},
   "source": [
    "# TRAINING STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c676bf3-8e6b-4163-87f2-b4a389b7682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_MODEL_REGISTRY_PATH = f\"s3://{default_bucket}/packaged-models/\"\n",
    "\n",
    "training_estimator = Estimator(image_uri=TRAINING_IMAGE,\n",
    "                      role=ROLE,\n",
    "                      entry_point='yolo_code/smoke_train.py',\n",
    "                      instance_count=1,\n",
    "                      instance_type='ml.g4dn.xlarge',#'ml.m5.2xlarge',\n",
    "                      hyperparameters={\n",
    "                          'model': model_param,\n",
    "                          'epochs': epochs_param,\n",
    "                          'batch': batch_size_param,\n",
    "                          'patience': patience_param,\n",
    "                          'optimizer': optimizer_param,\n",
    "                          'initial_learning_rate': ilr_param,\n",
    "                          'final_learning_rate': flr_param\n",
    "                      },\n",
    "                      output_path=S3_MODEL_REGISTRY_PATH,\n",
    "                      sagemaker_session=SAGEMAKER_SESSION,\n",
    "                      source_dir=\".\")\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    name=\"YOLO-Training\",\n",
    "    estimator=training_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs['train_data'].S3Output.S3Uri,\n",
    "            content_type=\"application/x-recordio\"\n",
    "        ),\n",
    "        \"val\": TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs['val_data'].S3Output.S3Uri,\n",
    "            content_type=\"application/x-recordio\"\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1090a4-2bfa-4f91-aef7-a014b66e51ed",
   "metadata": {},
   "source": [
    "# EVALUATION STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33309cf6-466e-4253-883f-fb274f61e366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MODEL_EVALUTION_PATH = f\"s3://{default_bucket}\"\n",
    "EVALUATION_METRICS_FOLDER = f\"val-results-{datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "script_eval = FrameworkProcessor(\n",
    "    estimator_cls=PyTorch,\n",
    "    framework_version='2.2.0',\n",
    "    py_version='py310',\n",
    "    instance_type='ml.t3.xlarge',\n",
    "    instance_count=1,\n",
    "    base_job_name='YOLO-Evaluation',\n",
    "    role=ROLE,\n",
    "    sagemaker_session=PIPELINE_SESSION,\n",
    ")\n",
    "\n",
    "eval_args = script_eval.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination='/opt/ml/processing/model',\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=processing_step.properties.ProcessingOutputConfig.Outputs['test_data'].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/input'\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name='evaluation',\n",
    "            source='/opt/ml/processing/evaluation',\n",
    "            destination=f'{MODEL_EVALUTION_PATH}/{EVALUATION_METRICS_FOLDER}'\n",
    "        )\n",
    "    ],\n",
    "    code='yolo_code/smoke_evaluate.py'\n",
    ")\n",
    "\n",
    "evaluation_step = ProcessingStep(\n",
    "    name='YOLO-Evaluation',\n",
    "    step_args=eval_args,\n",
    "    property_files=[PropertyFile(    # Correct parameter name and wrap PropertyFile in a list\n",
    "        name=\"EvaluationReport\",\n",
    "        output_name=\"evaluation\",\n",
    "        path=\"metrics.json\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9160646e-897a-49c6-a81f-7bbe0364ea65",
   "metadata": {},
   "source": [
    "# STEP FOR CONDITIONAL MODEL REGISTRY PUSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eda71b85-3d50-41ee-aabd-9e004a32d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "mAP_threshold = 0.7\n",
    "\n",
    "fail_step = FailStep(\n",
    "    name=\"mAPFail\",\n",
    "    error_message=Join(on=\" \", values=[\"Execution failed due to mAP <\", mAP_threshold]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "375e390e-a667-4b3b-8d1a-979ecae36f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import Properties\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "METRICS_PATH = f's3://{MODEL_EVALUTION_PATH}/{EVALUATION_METRICS_FOLDER}/metrics.json'\n",
    "\n",
    "register_estimator = Estimator(image_uri=PROCESSING_IMAGE,\n",
    "                      role=ROLE,\n",
    "                      instance_count=1,\n",
    "                      instance_type='ml.t3.medium',\n",
    "                      sagemaker_session=SAGEMAKER_SESSION\n",
    "                     )\n",
    "\n",
    "register_model_step = RegisterModel(\n",
    "    name=\"YOLOTrainedModel\",\n",
    "    estimator=register_estimator,\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_name,\n",
    "    approval_status=\"PendingManualApproval\",\n",
    "    description=f\"Model metrics available at {METRICS_PATH}\"\n",
    ")\n",
    "\n",
    "condition_check = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluation_step.name,\n",
    "        property_file=\"EvaluationReport\",  # Just use the PropertyFile name as a string\n",
    "        json_path=\"mAP\"\n",
    "    ),\n",
    "    right=mAP_threshold\n",
    ")\n",
    "\n",
    "registry_condition_step = ConditionStep(\n",
    "    name=\"YOLO-ModelRegistration\",\n",
    "    conditions=[condition_check],\n",
    "    if_steps=[register_model_step],\n",
    "    else_steps=[fail_step]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d6cdb7-45ff-4815-8f0d-40aac958750d",
   "metadata": {},
   "source": [
    "# SETUP FINAL PIPELINE WITH ALL STEPS AND INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8679d1fe-611d-4e4a-bd2a-45b1f55881cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://sagemaker-us-east-1-211125368524/E2E-Smoke-Detection-Pipeline/code/426062adfd5478d0e509f6c3027e7b73/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-east-1-211125368524/E2E-Smoke-Detection-Pipeline/code/0ff95e6702f0700d1aa530170082a883/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreatePipeline operation: PropertyFile must reference a valid processing step property file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m\n\u001b[1;32m      1\u001b[0m PIPELINE_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE2E-Smoke-Detection-Pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[1;32m      4\u001b[0m     name\u001b[38;5;241m=\u001b[39mPIPELINE_NAME,\n\u001b[1;32m      5\u001b[0m     parameters\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     steps\u001b[38;5;241m=\u001b[39m[processing_step, training_step, evaluation_step, registry_condition_step]\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 26\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole_arn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mROLE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/pipeline.py:297\u001b[0m, in \u001b[0;36mPipeline.upsert\u001b[0;34m(self, role_arn, description, tags, parallelism_config)\u001b[0m\n\u001b[1;32m    295\u001b[0m error_message \u001b[38;5;241m=\u001b[39m ce\u001b[38;5;241m.\u001b[39mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidationException\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready exists\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message):\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ce\n\u001b[1;32m    298\u001b[0m \u001b[38;5;66;03m# already exists\u001b[39;00m\n\u001b[1;32m    299\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(role_arn, description, parallelism_config\u001b[38;5;241m=\u001b[39mparallelism_config)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/pipeline.py:292\u001b[0m, in \u001b[0;36mPipeline.upsert\u001b[0;34m(self, role_arn, description, tags, parallelism_config)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn AWS IAM role is required to create or update a Pipeline.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 292\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole_arn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallelism_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m ce:\n\u001b[1;32m    294\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m ce\u001b[38;5;241m.\u001b[39mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/pipeline.py:169\u001b[0m, in \u001b[0;36mPipeline.create\u001b[0;34m(self, role_arn, description, tags, parallelism_config)\u001b[0m\n\u001b[1;32m    164\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_args(role_arn, description, parallelism_config)\n\u001b[1;32m    165\u001b[0m update_args(\n\u001b[1;32m    166\u001b[0m     kwargs,\n\u001b[1;32m    167\u001b[0m     Tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    168\u001b[0m )\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/botocore/client.py:1017\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1014\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreatePipeline operation: PropertyFile must reference a valid processing step property file."
     ]
    }
   ],
   "source": [
    "PIPELINE_NAME = \"E2E-Smoke-Detection-Pipeline\"\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=PIPELINE_NAME,\n",
    "    parameters=[\n",
    "        s3_bucket_param,\n",
    "        s3_folder_param,\n",
    "        train_ratio_param,\n",
    "        model_param,\n",
    "        epochs_param,\n",
    "        batch_size_param,\n",
    "        patience_param,\n",
    "        optimizer_param,\n",
    "        ilr_param,\n",
    "        flr_param,\n",
    "        mAP_threshold,\n",
    "        mAP50_threshold,\n",
    "        mAP75_threshold,\n",
    "        precisionthreshold,\n",
    "        recallthreshold,\n",
    "        model_package_name\n",
    "    ],\n",
    "    steps=[processing_step, training_step, evaluation_step, registry_condition_step]\n",
    ")\n",
    "\n",
    "pipeline.upsert(role_arn=ROLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215af8f-d085-4e67-a2cb-2a1097023e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971dda07-965e-4b80-9463-47ce31443ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
